#include <iostream>
#include <fstream>
#include <sstream>
#include <unordered_map>
#include <vector>
#include <chrono>
#include <cmath>
#include <algorithm>

// Include your provided headers
#include "dataset.h"       // DataPoint struct, loadDataset(), euclideanDistance
#include "hnsw_wrapper.h"  // HNSWWrapper class
#include "bplustreecpp.h"  // BPlusTree class

using namespace std;

// Global map: attribute value -> vector of dataset indices
static unordered_map<double, vector<size_t>> attributeMap;

/********************************************************************/
/***                    HELPER FUNCTIONS                          ***/
/********************************************************************/

// Brute force Top-K within a given subset of indices
vector<pair<float, size_t>> bruteForceTopK(
    const vector<DataPoint> &dataset,
    const vector<size_t> &subsetIndices,
    const vector<float> &queryVec,
    size_t k)
{
    vector<pair<float, size_t>> distID;
    distID.reserve(subsetIndices.size());

    for (auto idx : subsetIndices) {
        float dist = euclideanDistance(dataset[idx].coords, queryVec);
        distID.push_back({dist, idx});
    }
    if (k > distID.size()) k = distID.size();

    std::partial_sort(distID.begin(), distID.begin() + k, distID.end(),
        [](auto &a, auto &b) { return a.first < b.first; }
    );
    distID.resize(k);
    return distID;
}

// Brute force Top-K on the ENTIRE dataset
vector<pair<float, size_t>> bruteForceTopKEntire(
    const vector<DataPoint> &dataset,
    const vector<float> &queryVec,
    size_t k)
{
    vector<size_t> allIndices(dataset.size());
    for (size_t i = 0; i < dataset.size(); i++) {
        allIndices[i] = i;
    }
    return bruteForceTopK(dataset, allIndices, queryVec, k);
}

/** Metrics **/

// Compute Precision@k = (# of correct hits) / (k in approx)
double computePrecisionK(const vector<size_t> &approx, const vector<size_t> &gt) {
    // Convert gt to a set for quick membership check
    unordered_set<size_t> gtSet(gt.begin(), gt.end());
    size_t correct = 0;
    for (auto &idx: approx){
        if(gtSet.find(idx) != gtSet.end()) correct++;
    }
    return approx.empty() ? 1.0 : (double)correct / (double)approx.size();
}

// Compute Recall@k = (# of correct hits) / (k in ground truth)
double computeRecallK(const vector<size_t> &approx, const vector<size_t> &gt) {
    // Convert approx to a set for quick membership check
    unordered_set<size_t> approxSet(approx.begin(), approx.end());
    size_t correct = 0;
    for (auto &idx: gt){
        if(approxSet.find(idx) != approxSet.end()) correct++;
    }
    return gt.empty() ? 1.0 : (double)correct / (double)gt.size();
}

// A simple Accuracy metric = intersection_size / k
// (Similar to Precision@k, but we can keep it separate if you'd like to see it explicitly.)
double computeAccuracy(const vector<size_t> &approx, const vector<size_t> &gt) {
    unordered_set<size_t> gtSet(gt.begin(), gt.end());
    size_t correct = 0;
    for (auto &idx: approx){
        if(gtSet.find(idx) != gtSet.end()) correct++;
    }
    return approx.empty() ? 1.0 : (double)correct / (double)approx.size();
}

/********************************************************************/
/***                           MAIN                               ***/
/********************************************************************/
int main(int argc, char** argv) {
    if (argc < 2) {
        cerr << "Usage: " << argv[0] << " <dataset_file> [queries_file]\n";
        return 1;
    }
    string datasetFile = argv[1];

    // 1. Load dataset
    vector<DataPoint> dataset;
    size_t d;
    cout << "Loading dataset from " << datasetFile << "\n";
    if (!loadDataset(datasetFile, dataset, d)) {
        cerr << "Failed to load dataset.\n";
        return 1;
    }
    size_t N = dataset.size();
    cout << "Dataset has " << N << " points in dimension " << d << "\n";

    // 2. Build the B+‐tree. Also fill our attributeMap
    double degree = 500; // You can pick any suitable "degree" (fanout)
    BPlusTree bpt(degree);

    // Timing for B+‐tree build
    auto startBPT = chrono::steady_clock::now();
    for (size_t i = 0; i < N; i++) {
        double attr = dataset[i].attribute;
        bpt.insert(attr);
        attributeMap[attr].push_back(i);
    }
    auto endBPT = chrono::steady_clock::now();
    double buildTimeBPT_ms = chrono::duration_cast<chrono::milliseconds>(endBPT - startBPT).count();
    cout << "B+ tree built on 'attribute' for " << N << " records.\n";

    // 3. Build global HNSW index on the entire dataset
    cout << "Building global HNSW index for " << N << " points...\n";
    auto startHNSW = chrono::steady_clock::now();
    HNSWWrapper globalHNSW(d, N);
    for (size_t i = 0; i < N; i++) {
        globalHNSW.addPoint(dataset[i].coords.data(), i);
    }
    auto endHNSW = chrono::steady_clock::now();
    double buildTimeHNSW_ms = chrono::duration_cast<chrono::milliseconds>(endHNSW - startHNSW).count();

    // We'll store all benchmark results in a .txt file
    ofstream resultFile("benchmark_results.txt");
    if(!resultFile.is_open()){
        cerr << "Could not open benchmark_results.txt for writing.\n";
        return 1;
    }

    // Write build times
    resultFile << "=== Build Times (milliseconds) ===\n";
    resultFile << "B+Tree Build Time: " << buildTimeBPT_ms << " ms\n";
    resultFile << "HNSW Build Time  : " << buildTimeHNSW_ms << " ms\n\n";

    // If we have a queries_file as second argument, load queries
    if (argc >= 3) {
        ifstream qin(argv[2]);
        if(!qin.is_open()){
            cerr << "Could not open queries file: " << argv[2] << "\n";
            return 1;
        }
        size_t Q;
        qin >> Q; // number of queries
        cout << "Read " << Q << " queries from file.\n";

        // We'll store per‐query metrics in these
        vector<double> allPrec, allRecall, allAcc;

        for (size_t qIdx = 0; qIdx < Q; qIdx++) {
            vector<float> queryVec(d);
            for(size_t j = 0; j < d; j++){
                qin >> queryVec[j];
            }
            float a_min, a_max;
            qin >> a_min >> a_max;
            size_t k;
            qin >> k;

            if(!qin) {
                cerr << "Error reading query\n";
                break;
            }

            // 1) B+‐tree range search to get candidate subset
            auto startQuery = chrono::steady_clock::now();
            auto [count, attrVals] = bpt.rangeSearch(a_min, a_max);

            // Convert attributes -> candidate IDs 
            vector<size_t> candidateIDs;
            candidateIDs.reserve(count);
            for (double val : attrVals) {
                auto &inds = attributeMap[val];
                candidateIDs.insert(candidateIDs.end(), inds.begin(), inds.end());
            }

            // We'll store the approximate topK indices
            vector<size_t> approxIndices;

            /****************************************************/
            /**   Ground Truth Logic for Each Scenario         **/
            /****************************************************/
            // If the candidate set is small => "brute force" scenario:
            //   - The "ground truth" for this scenario should be top‐k from *candidateIDs only*.
            //   - Then we measure how well the found topK matches that ground truth.
            //
            // If the candidate set is large => "HNSW" scenario:
            //   - The ground truth remains top‐k from the ENTIRE dataset (the original approach).
            //   - Then we measure approximate result vs the entire dataset ground truth.
            /****************************************************/

            const size_t threshold = 20;
            if (candidateIDs.size() <= threshold) {
                // *Brute force* approach on the candidateIDs
                // Ground truth is also from candidateIDs
                auto gtBrute = bruteForceTopK(dataset, candidateIDs, queryVec, k);
                vector<size_t> gtIndices; gtIndices.reserve(gtBrute.size());
                for (auto &p: gtBrute) {
                    gtIndices.push_back(p.second);
                }

                // The approximate result is the same brute force (i.e., no difference),
                // but let's keep logic consistent:
                // We'll do the same brute force call for the "approxIndices."
                auto approxTopK = bruteForceTopK(dataset, candidateIDs, queryVec, k);
                for (auto &p: approxTopK) {
                    approxIndices.push_back(p.second);
                }

                auto endQuery = chrono::steady_clock::now();
                double queryTime_ms = chrono::duration_cast<chrono::microseconds>(endQuery - startQuery).count() / 1000.0;

                // Evaluate metrics vs ground truth from candidateIDs
                double precK = computePrecisionK(approxIndices, gtIndices);
                double recallK = computeRecallK(approxIndices, gtIndices);
                double acc    = computeAccuracy(approxIndices, gtIndices);

                allPrec.push_back(precK);
                allRecall.push_back(recallK);
                allAcc.push_back(acc);

                resultFile << "Query #" << (qIdx+1) << " (Brute Force scenario):\n";
                resultFile << "  CandidateIDs.size() = " << candidateIDs.size() << "\n";
                resultFile << "  QueryTime (ms) = " << queryTime_ms << "\n";
                resultFile << "  Precision@k = " << precK << "\n";
                resultFile << "  Recall@k = " << recallK << "\n";
                resultFile << "  Accuracy = " << acc << "\n";
                resultFile << "-----------------------------------\n";

            } else {
                // *HNSW* approach on the entire dataset
                // Ground truth is top‐k from the ENTIRE dataset
                auto gtTopK = bruteForceTopKEntire(dataset, queryVec, k);
                vector<size_t> gtIndices; gtIndices.reserve(gtTopK.size());
                for(auto &p: gtTopK) {
                    gtIndices.push_back(p.second);
                }

                // Now approximate retrieval using global HNSW
                auto topk = globalHNSW.searchKnn(queryVec.data(), k, /*efSearch=*/100);
                auto endQuery = chrono::steady_clock::now();
                double queryTime_ms = chrono::duration_cast<chrono::microseconds>(endQuery - startQuery).count() / 1000.0;

                vector<size_t> hnswIndices; hnswIndices.reserve(topk.size());
                for (auto &r : topk) {
                    hnswIndices.push_back(r.second);
                }
                approxIndices = hnswIndices; // for clarity

                // Evaluate metrics vs the entire‐dataset ground truth
                double precK = computePrecisionK(approxIndices, gtIndices);
                double recallK = computeRecallK(approxIndices, gtIndices);
                double acc    = computeAccuracy(approxIndices, gtIndices);

                allPrec.push_back(precK);
                allRecall.push_back(recallK);
                allAcc.push_back(acc);

                resultFile << "Query #" << (qIdx+1) << " (HNSW scenario):\n";
                resultFile << "  CandidateIDs.size() = " << candidateIDs.size() << "\n";
                resultFile << "  QueryTime (ms) = " << queryTime_ms << "\n";
                resultFile << "  Precision@k = " << precK << "\n";
                resultFile << "  Recall@k = " << recallK << "\n";
                resultFile << "  Accuracy = " << acc << "\n";
                resultFile << "-----------------------------------\n";
            }
        }
        qin.close();

        // Summaries
        if (!allPrec.empty()) {
            double avgPrec = 0.0, avgRecall = 0.0, avgAcc = 0.0;
            for (size_t i = 0; i < allPrec.size(); i++){
                avgPrec   += allPrec[i];
                avgRecall += allRecall[i];
                avgAcc    += allAcc[i];
            }
            avgPrec   /= (double) allPrec.size();
            avgRecall /= (double) allRecall.size();
            avgAcc    /= (double) allAcc.size();

            resultFile << "\n=== Aggregate Metrics over " << allPrec.size() << " queries ===\n";
            resultFile << "Average Precision@k : " << avgPrec << "\n";
            resultFile << "Average Recall@k    : " << avgRecall << "\n";
            resultFile << "Average Accuracy    : " << avgAcc << "\n";
        }

    } else {
        cout << "No queries file provided, interactive mode not benchmarked.\n";
    }

    resultFile.close();
    cout << "Done. Results written to benchmark_results.txt\n";
    return 0;
}
